# ğŸŸª SubSplit

### **"Because your clips deserve more than subtitles thrown on with a prayer."**

**SubSplit** is a local-first, GPU-aware subtitle tool made for streamers, YouTubers, and overengineers who'd rather automate their captions than ever open Premiere Pro again.

Powered by [OpenAI's Whisper](https://github.com/openai/whisper) and [PyAnnote](https://github.com/pyannote/pyannote-audio), SubSplit doesn't just slap text on screen:

- ğŸ§  **Diarizes** who's talkingâ€”even in chaotic Discord calls.
- ğŸ¨ **Color-codes** speakers for clarity (WIP).
- ğŸ–‹ï¸ **Burns clean .ass subtitles** into your video with FFmpeg.
- ğŸ”„ **Processes multiple files** in batches.
- ğŸ–±ï¸ **Drag-and-drop UI** with ETA and job feedback.

---

## âš™ï¸ Features (Working)

- ğŸ¤ **Speaker Diarization** â€” Detect and separate speakers.
- ğŸ§  **Whisper Transcription** â€” Uses large model locally via GPU.
- ğŸ”¥ **Replay-bufferâ€‘friendly Design** â€” Fast processing, no cloud calls.
- ğŸ’¾ **Embedded Subtitle Export** â€” .ass subtitles burned directly into MP4.
- âš« **Dark Mode UI** â€” Built-in and non-negotiable.
- ğŸ§  **Local Database** â€” Keeps track of processed videos.

---

## ğŸš§ Work In Progress

- ğŸ¨ Per-speaker subtitle color styling
- ğŸ§ª Funny moment detection / smart highlight tagging
- ğŸª„ OBS Replay Buffer Marker integration
- ğŸ–¼ï¸ UI polish: logo display, progress bar improvements
- ğŸ—‚ï¸ Folder watcher + auto-process queue
- ğŸ§  WebSocket-powered Web UI (React/Tailwind rewrite plan)

---

## ğŸ–¥ï¸ Showcase (WIP UI)

![SubSplit UI](assets/ui_preview.png)

UI built with plain HTML + TailwindCSS for now. No build step, just vibes.

---

## ğŸš€ Getting Started

```bash
git clone https://github.com/Dyhrr/SubSplit
cd SubSplit
pip install -r requirements.txt
python run.py  # or cli.py if you're hardcore
```

â— Make sure you have:
- [FFmpeg](https://ffmpeg.org/download.html) in PATH
- HuggingFace token for diarization model
- Whisper + Torch installed

---

## ğŸ§  Tech Stack

- ğŸ **Python 3.11**
- ğŸ”Š **Whisper (large)** â€” Transcription
- ğŸ§ **PyAnnote** â€” Diarization
- ğŸ¨ **ASS subtitles** â€” Color-ready format
- ğŸ¥ **FFmpeg** â€” Video burn-in
- ğŸ–¥ï¸ **Tailwind UI** â€” Basic dark-mode frontend
- âš™ï¸ **FastAPI + Uvicorn** â€” Local API layer

---

## ğŸ“¦ Roadmap

- [ ] OBS Replay Buffer marker extraction
- [ ] Color-coded speaker styles in subtitles
- [ ] Highlight tagging & smart funny-moment clustering
- [ ] Web interface using React + shadcn/ui
- [ ] Auto-installer + packaging with PyInstaller
- [ ] Voice separation pre-processing (experimental)

---

## ğŸ Known Issues

- ğŸ§  PyAnnote model is from 0.x â€” expect logs to whine about version mismatch.
- ğŸ–¼ï¸ Some .svg logos render oddly in-app, may fallback to .png.
- ğŸ’¥ Using large Whisper model without GPU will destroy your will to live.

---

## ğŸ§™ Author

### Nick / Dyhrrr

Builder. Breaker. Tweaker. Danish. Not a UX designer.

ğŸ“¬ Want to flame, help, or say hi? [Open an issue](https://github.com/Dyhrr/SubSplit/issues)

---

## ğŸ›¡ License

MIT License. No bullshit. Attribution appreciated.

Use it, improve it, ship it. Just donâ€™t resell it as a SaaS and pretend you built it alone.
